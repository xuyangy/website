---
title: "WGS Upscaling - NSC Storage Capacity"
title-block-banner: true
image: "storage.png"
description: "NSC storage capability"
author: 
    - name: Xuyang Yuan
      email: "xuyangy@uio.no"
      affiliation: "GDx OUSAMG"
      url: "https://www.robotgenome.com"
      role: "collect data"
date: last-modified
format: 
    html:
        css: style.css
        toc: true
        toc-depth: 6
        toc-expand: true
        number-sections: true
        number-depth: 6
        float: true
        smooth-scroll: true
        header-includes: |
            <link rel="preconnect" href="https://fonts.googleapis.com">
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Quicksand&display=swap" rel="stylesheet">
            <link href="https://fonts.googleapis.com/css2?family=Krona+One&display=swap" rel="stylesheet">
        grid:
            sidebar-width: 100px
            body-width: 1100px
            margin-width: 420px
knitr: true
comments: 
    hypothesis: false
execute: 
    cache: false
    echo: false
    message: false
    warning: false
---


```{=html}
<script>
document.addEventListener('DOMContentLoaded', () => {
  const targetElements = document.querySelectorAll('[id]');
  targetElements.forEach(el => {
    const observer = new IntersectionObserver(entries => {
      entries.forEach(entry => {
        if (entry.isIntersecting && window.location.hash === '#' + el.id) {
          el.scrollIntoView({ behavior: 'smooth', block: 'center' });
        }
      });
    });
    observer.observe(el);
  });
});
</script>
```


# Background
<hr>

GDx at OUSAMG is planning to upscale the WGS production to `192` samples (`4 x 48` or `2 x 48 + 1 x 96`) samples per week. 
Do we have enough capacity in IT and bioinformatics pipelines for this upscaling?

The capacity of IT & bioinformatics pipelines can be evaluated from following three aspects:

1. [Data transfer speed](https://robotgenome.com/projects/wgs_upscale/wgs_upscaling_bioinf.html)
2. Data storage
3. [Pipeline capacity](https://robotgenome.com/projects/wgs_upscale/wgs_upscaling_bioinf_pipeline.html)


**This document will focus on the evaluation of NSC storage capacity.**

# Boston capacity breakdown

Total capacity of boston is `552.6 TiB`. 

::: {.callout-warning}
### [As of Dec 29, 2024, 12:00 PM]{style="color:red"}
The capability breakdown as of Dec 29, 2024 12:00 PM is as follows:
:::

![](capacity_breakdown.png){width="750"}


# Boston usable capacity
::: {.callout-warning}
### [As of Dec 29, 2024, 12:00 PM]{style="color:red"}
The usable capacity as of Dec 29, 2024, 12:00 PM is `231.2 TiB`.
:::

![](usable_capacity.png){width="550"}


# Boston storage volumes

| Name                                                                                  | Purpose                               |
| -----                                                                                 | ---                                   |
| [/boston]{style="font-family:courier"}                                                | General data area                     |
| [/boston/runScrach]{style="font-family:courier"}                                      | Sequencing runs (Illumina, ONT)       |
| [/boston/projects]{style="font-family:courier"}                                       | Research projects                     |
| [/boston/common]{style="font-family:courier"}                                         | Software, and repositories            |
| [/boston/diag]{style="font-family:courier"}                                           | Diagnostics production                |
| [/boston/diag/transfer]{style="font-family:courier"}                                  | Transfer area (for TSD)               |
| [/boston/runScratch/demultiplexed/delivery/tsd_sleipnir]{style="font-family:courier"} | Transfer area NSC                     |
| [vm-datastore]{style="font-family:courier"}                                           | VMware datastore (virtual hard disks) |


# Boston used storage breakdown
::: {.callout-warning}
### [As of Dec 29, 2024, 12:00 PM:]{style="color:red"}
The used storage as of Dec 29, 2024, 12:00 PM is `228 TiB`. Details are as follows:
:::


```{python}
#| label: fig-nsc_storage_used
#| fig-cap: sunburst chart of used boston storage as of Dec 29, 2024 12:00 PM

import pandas as pd
import plotly.express as px

df = pd.read_csv(
    "nsc_storage.csv",
    dtype={"Folder": str, "Parent": str, "Size": float, "DisplaySize": str},
)
df = df.fillna("")
fig = px.sunburst(
    df, names="Folder", parents="Parent", values="Size", branchvalues="remainder"
)
disp = list(df["DisplaySize"])
fig = fig.update_traces(
    hovertemplate="Folder: %{currentPath}%{label}<br>Size: %{text} (%{percentParent:.1%})",
    text=disp,
)
fig.update_layout(margin=dict(t=20, l=0, r=0, b=20), height=900)
```

::: {.callout-tip}
The size of `boston/diag/production/data/samples` folder is very small (924 GiB) for 255 sample folders in it due to
the big files (mainly `.fastq.ora` files) are hardlinks.
:::


# Miami (old boston) capacity breakdown

Total capacity of miami storage is `519 TiB`. 

::: {.callout-warning}
### [As of Nov 24, 2024, 12:06 PM]{style="color:red"}
The capability breakdown as of Nov 24, 2024 12:06 PM is as follows:
:::

![](miami_storage_20241124.png){width="950"}


# Miami (old boston) used storage breakdown
::: {.callout-warning}
### [As of Nov 24, 2024, 12:06 PM:]{style="color:red"}
The used storage as of Nov 24, 204, 12:06 PM is `385 TiB`. Details are as follows:
:::


```{python}
#| label: fig-miami_storage_used
#| fig-cap: sunburst chart of used miami storage as of Nov 24, 2024 12:06 PM

import pandas as pd
import plotly.express as px

df_miami = pd.read_csv(
    "miami_storage.csv",
    dtype={"Folder": str, "Parent": str, "Size": float, "DisplaySize": str},
)
df_miami = df_miami.fillna("")
fig_miami = px.sunburst(
    df_miami, names="Folder", parents="Parent", values="Size", branchvalues="remainder"
)
disp_miami = list(df_miami["DisplaySize"])
fig_miami = fig_miami.update_traces(
    hovertemplate="Folder: %{currentPath}%{label}<br>Size: %{text} (%{percentParent:.1%})",
    text=disp_miami,
)
fig_miami.update_layout(margin=dict(t=20, l=0, r=0, b=20), height=900)
```

::: {.callout-warning}
### Warning diag
Even after the routine diagnostics production cleanup, diag still uses a large volume storage.

The following folders take ~`80 TiB` in total, which can be considered for cleanup:

| Folder                                   | Size       |
| :--------                                | ---:       |
| `/miami/diag/diagInternal/ying_temp`    | `24.0 TiB` |
| `/miami/diag/runs/veriseq`              | `13.2 TiB` |
| `/miami/diag/staging/data`              | `12.5 TiB` |
| `/miami/diag/transfer/dev/p22-yingsh`   | `11.3 TiB` |
| `/miami/diag/transfer/lost-and-found`   | `9.6 TiB`  |
| `/miami/diag/diagInternal/verification` | `4.1 TiB`  |
| `/miami/diag/staging/transfer`          | `4.0 TiB`  |

:::


::: {.callout-warning}
### Warning NSC

The `/miami/projects` folder takes `104 TiB`.

The `/miami/runScratch/analysis/projects` folder takes `55 TiB`.
:::

# Boston used storage table
<hr>

::: {style="font-family:courier"}

## [/boston]{style="font-family:courier"} (228 TiB)    

| Directory                                             | Logical  | %use of Parent Directory | Physical |
| -----------                                           | -----    | --------                 | -----    |
| [/boston/]{.commonDir}[diag](#boston-diag)            | 96.9 TiB | 51.8%                    | 113 TiB  |
| [/boston/]{.commonDir}[runScrach](#boston-runscratch) | 83.1 TiB | 44.4%                    | 107 TiB  |
| [/boston/]{.commonDir}projects                        | 2.87 TiB | 1.5%                     | 3.74 TiB |
| [/boston/]{.commonDir}home                            | 2.77 TiB | 1.5%                     | 2.82 TiB |
| [/boston/]{.commonDir}common                          | 1.42 TiB | 0.8%                     | 1.54 TiB |
: {.striped .hover}

:::

### [/boston/diag]{#boston-diag style="font-family:courier"}

::: {style="font-family:courier"}
| Directory                                                        | Logical  | %use of Parent Directory | Physical |
| -----------                                                      | -----    | --------                 | -----    |
| [/boston/diag/]{.commonDir}runs                                  | 35.8 TiB | 37.0%                    | 47.4 TiB |
| [/boston/diag/]{.commonDir}[production](#boston-diag-production) | 33.8 TiB | 34.9%                    | 34.3 TiB |
| [/boston/diag/]{.commonDir}[transfer](#boston-diag-transfer)     | 15.6 TiB | 16.1%                    | 16.3 TiB |
| [/boston/diag/]{.commonDir}nscDelivery                                         | 7.82 TiB | 8.1%                     | 10.4 TiB |
| [/boston/diag/]{.commonDir}[staging](#boston-diag-staging)       | 3.84 TiB | 4.0%                     | 4.88 TiB |
| [/boston/diag/]{.commonDir}diagInternal                          | 1.48 GiB | 0.0%                     | 1.88 GiB |
: {.striped .hover}
:::


#### [/boston/diag/production]{#boston-diag-production style="font-family:courier"}


::: {style="font-family:courier"}
| Directory                                         | Logical  | %use of Parent Directory | Physical |
| -----------                                       | -----    | --------                 | -----    |
| [/boston/diag/production/]{.commonDir}data        | 33.5 TiB | 99.1%                    | 33.9 TiB |
| [/boston/diag/production/]{.commonDir}sw          | 238  GiB | 0.7%                     | 297  GiB |
| [/boston/diag/production/]{.commonDir}reference   | 74.3 GiB | 0.2%                     | 63.9 GiB |
| [/boston/diag/production/]{.commonDir}logs        | 3.32 GiB | 0.0%                     | 557  MiB |
| [/boston/diag/production/]{.commonDir}.thirdparty | 110  MiB | 0.0%                     | 148  GiB |
:::


#### [/boston/diag/transfer]{#boston-diag-transfer style="font-family:courier"}
::: {style="font-family:courier"}
| Directory                                      | Logical  | %use of Parent Directory | Physical |
| -----------                                    | -----    | --------                 | -----    |
| [/boston/diag/transfer/]{.commonDir}production | 14.8 TiB | 97.7%                    | 15.4 TiB |
: {.striped .hover}
:::


#### [/boston/diag/staging]{#boston-diag-staging style="font-family:courier"}
::: {style="font-family:courier"}
| Directory                                    | Logical  | %use of Parent Directory | Physical |
| -----------                                  | -----    | --------                 | -----    |
| [/boston/diag/]{.commonDir}staging/data      | 3.53 TiB | 92.0%                    | 4.54 TiB |
| [/boston/diag/]{.commonDir}staging/sw        | 237 GiB  | 6.0%                     | 285 GiB  |
| [/boston/diag/]{.commonDir}staging/reference | 77.5 GiB | 2.0%                     | 67.5 GiB |
: {.striped .hover}
:::


### [/boston/runScratch]{#boston-runscratch style="font-family:courier"}
::: {style="font-family:courier"}
| Directory                                         | Logical  | %use of Parent Directory | Physical |
| -----------                                       | -----    | --------                 | -----    |
| [/boston/runScratch/]{.commonDir}NovaSeqX         | 34.5 TiB | 41.5%                    | 45.7 TiB |
| [/boston/runScratch/]{.commonDir}analysis         | 38.8 TiB | 37.0%                    | 37.1 TiB |
| [/boston/runScratch/]{.commonDir}demultiplexed    | 15.6 TiB | 18.8%                    | 20.7 TiB |
| [/boston/runScratch/]{.commonDir}processed        | 1.03 TiB | 1.2%                     | 1.58 TiB |
| [/boston/runScratch/]{.commonDir}ONT              | 738 GiB  | 0.9%                     | 1.02 TiB |
| [/boston/runScratch/]{.commonDir}UserData         | 244 GiB  | 0.3%                     | 254 GiB  |
| [/boston/runScratch/]{.commonDir}test             | 64.7 GiB | 0.1%                     | 86.1 GiB |
| [/boston/runScratch/]{.commonDir}PGT              | 16.7 GiB | 0.0%                     | 20.5 GiB |
| [/boston/runScratch/]{.commonDir}Upgrade_software | 16.7 GiB | 0.0%                     | 22.2 GiB |
| [/boston/runScratch/]{.commonDir}mik_data         | 12.5 GiB | 0.0%                     | 12.5 GiB |
| [/boston/runScratch/]{.commonDir}imm_data         | 4.5 GiB  | 0.0%                     | 4.53 GiB |
: {.striped .hover}
:::


# Expected data
The data generated by NovaSeqX depend on the settings of secondary analysis and 
the sequencing depth (current setting is 64 samples per flowcell).

When use Onboard DRAGEN only for demultiplexing, inhouse pipelines must be run on external DRAGEN.


## Per sample estimation

### BCL Convert only

#### NovaSeqX generated data
The `{R1,R2}.fastq.ora` files per sample is about `14 GB` logical data (`18 GB` on disk).

Other files such as BCL files, images, logs, reports, etc. is about `47 GB` logical data per sample (`63 GB` on disk).

::: {.callout-important}
### Subtotal
[In total, `61 GB` logical data per sample (`81 GB` on disk).]{#bcl-convert-data-1}
:::

#### Inhouse pipelines on external DRAGEN
With BCL Convert only, we need to run inhouse pipelines on external DRAGEN which requires input data and also generates output data.

Given the design of the inhouse pipelines, some files are duplicated in different locations.

1. Only 1 copy of any _fastq.ora_ file is physically stored on boston, _i.e.,_ not duplicated. A _fastq.ora_ file appears in 4 different locations:

    (@) `/boston/diag/nscDelivery`
    (@) `/boston/diag/transfer/production/{normal,high,urgent}/samples` or `/boston/daig/transfer/production/transferred/{normal,high,urgent}/samples`
    (@) `/boston/diag/production/data/samples`
    (@) `/boston/diag/production/data/analyses-work/\*/result/\*/work`

    > [1]{.mono}, [2]{.mono} and [3]{.mono} are hardlinks; [4]{.mono} is symlink of [3]{.mono} (within `/boston/diag/produciton/data/analyses-work`, files are symlinked from the Nextflow [work]{.mono} folder.)

2. Files in `/boston/diag/produciton/data/analyses-results/{singles,trios}` are copies of that in `/boston/diag/produciton/data/analyses-work`

3. Files in `/boston/diag/transfer/production/{normal,high,urgent}/analyses-results/{singles,trios}` are copies of that in `/boston/diag/produciton/data/analyses-work`


##### analyses-work folder size
```{python}
#| cache: false
import plotly.graph_objects as go
from numpy import mean

analyses_work_dirs_basepipe_data = [63, 63, 66, 66, 66, 66, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 76, 76, 76, 77, 77, 77, 78, 78, 80, 80, 82]
mean_analyses_work_dirs_basepipe_data = mean(analyses_work_dirs_basepipe_data)
analyses_work_dirs_basepipe_disk = [61, 61, 64, 64, 65, 65, 65, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 75, 75, 76, 76, 77, 77, 78, 78, 78, 79]
analyses_work_dirs_triopipe_data = [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13]
analyses_work_dirs_triopipe_disk = [7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.2, 7.2, 7.2, 7.3, 7.3, 8.3]
analyses_work_dirs_annopipe_data = [6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 7.0, 7.0, 7.0, 7.0, 7.0, 7.2, 7.3, 7.4, 7.4, 7.4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 21]
analyses_work_dirs_annopipe_disk = [6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.3, 6.3, 6.3, 6.4, 6.4, 6.4, 6.5, 6.6, 6.7, 6.7, 6.7, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 19]
mean_analyses_work_dirs_basepipe_data = mean(analyses_work_dirs_basepipe_data)
mean_analyses_work_dirs_basepipe_disk = mean(analyses_work_dirs_basepipe_disk)
mean_analyses_work_dirs_triopipe_data = mean(analyses_work_dirs_triopipe_data)
mean_analyses_work_dirs_triopipe_disk = mean(analyses_work_dirs_triopipe_disk)
mean_analyses_work_dirs_annopipe_data = mean(analyses_work_dirs_annopipe_data)
mean_analyses_work_dirs_annopipe_disk = mean(analyses_work_dirs_annopipe_disk)
mean_analyses_work_data = \
    mean(analyses_work_dirs_basepipe_data) \
    + sum(analyses_work_dirs_triopipe_data) / len(analyses_work_dirs_basepipe_data) \
    + sum(analyses_work_dirs_annopipe_data) / len(analyses_work_dirs_basepipe_data),
mean_analyses_work_data = mean_analyses_work_data[0]

mean_analyses_work_disk = \
    mean(analyses_work_dirs_basepipe_disk) \
    + sum(analyses_work_dirs_triopipe_disk) / len(analyses_work_dirs_basepipe_disk) \
    + sum(analyses_work_dirs_annopipe_disk) / len(analyses_work_dirs_basepipe_disk),
mean_analyses_work_disk = mean_analyses_work_disk[0]

fig1 = go.Figure(
    data=[
        go.Box(
            y=analyses_work_dirs_basepipe_data, boxpoints="all", name="basepipe (logical)"
        ),
        go.Box(
            y=analyses_work_dirs_basepipe_disk,
            boxpoints="all",
            name="basepipe (on disk)",
        ),
        go.Box(
            y=analyses_work_dirs_triopipe_data, boxpoints="all", name="triopipe (logical)"
        ),
        go.Box(
            y=analyses_work_dirs_triopipe_disk,
            boxpoints="all",
            name="triopipe (on disk)",
        ),
        go.Box(
            y=analyses_work_dirs_annopipe_data, boxpoints="all", name="annopipe (logical)"
        ),
        go.Box(
            y=analyses_work_dirs_annopipe_disk,
            boxpoints="all",
            name="annopipe (on disk)",
        ),
    ]
)
fig1 = fig1.update_layout(
    title="analyses-work directories size (GB)",
    yaxis_title="Size (GB)",
    height=900,
    width=1050,
    title_x=0.5,
    margin=dict(t=50, l=0, r=0, b=50),
    template="ggplot2",
)
# fig1 = fig1.update_traces(hovertemplate="Size: %{y} GB")
fig1.show()
```

```{r} 
library(reticulate)
r_mean_analyses_work_dirs_basepipe_data <- round(py$mean_analyses_work_dirs_basepipe_data)
r_mean_analyses_work_dirs_basepipe_disk <- round(py$mean_analyses_work_dirs_basepipe_disk)
r_mean_analyses_work_dirs_triopipe_data <- round(py$mean_analyses_work_dirs_triopipe_data)
r_mean_analyses_work_dirs_triopipe_disk <- round(py$mean_analyses_work_dirs_triopipe_disk)
r_mean_analyses_work_dirs_annopipe_data <- round(py$mean_analyses_work_dirs_annopipe_data)
r_mean_analyses_work_dirs_annopipe_disk <- round(py$mean_analyses_work_dirs_annopipe_disk)
r_mean_analyses_work_data <- py$mean_analyses_work_data
r_mean_analyses_work_disk <- py$mean_analyses_work_disk

```
::: {.callout-important}
### Subtotal

Average analyses-work basepipe folder size is
<code>`{r} r_mean_analyses_work_dirs_basepipe_data` GiB</code> 
(<code>`{r} r_mean_analyses_work_dirs_basepipe_disk` GiB</code>  on disk)

Average analyses-work triopipe folder size is
<code>`{r} r_mean_analyses_work_dirs_triopipe_data` GiB</code>
(<code>`{r} r_mean_analyses_work_dirs_triopipe_disk` GiB</code> on disk)

Average analyses-work annopipe folder size is 
<code>`{r} r_mean_analyses_work_dirs_annopipe_data` GiB</code>
(<code>`{r} r_mean_analyses_work_dirs_annopipe_disk` GiB</code> on disk)

[Adding [NovaSeqX generated data](#bcl-convert-data-1),
the total data per sample is <code>`{r} round(61 + r_mean_analyses_work_data)` GiB</code>
(<code>`{r} round(81 + r_mean_analyses_work_disk)` GiB</code> on disk).]{#bcl-convert-data-analyses-work}
 
:::

##### analyses-results folder size
```{python}
#| cache: false
import plotly.graph_objects as go

analyses_results_singles_data = [48, 48, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 61, 61, 61, 62, 62, 63]
analyses_results_singles_disk= [48, 48, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 61, 61, 61, 62, 62, 63]
analyses_results_trios_data = [2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 3.1]
analyses_results_trios_disk= [2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 3.1]
mean_analyses_results_singles_data = mean(analyses_results_singles_data)
mean_analyses_results_singles_disk = mean(analyses_results_singles_disk)
mean_analyses_results_trios_data =   mean(analyses_results_trios_data)
mean_analyses_results_trios_disk =   mean(analyses_results_trios_disk)
mean_analyses_results_data = mean(analyses_results_singles_data) + sum(analyses_results_trios_data) / len(analyses_results_singles_data)
mean_analyses_results_disk = mean(analyses_results_singles_disk) + sum(analyses_results_trios_disk) / len(analyses_results_singles_disk)

fig1 = go.Figure(
    data=[
        go.Box(y=analyses_results_singles_data, boxpoints="all", name="singles (logical)"),
        go.Box(y=analyses_results_singles_disk, boxpoints="all", name="singles (on disk)"),
        go.Box(y=analyses_results_trios_data, boxpoints="all", name="trios (logical)"),
        go.Box(y=analyses_results_trios_disk, boxpoints="all", name="trios (on disk)"),
    ]
)
fig1 = fig1.update_layout(
    title="analyses-results directories size (GB)",
    yaxis_title="Size (GB)",
    height=600,
    width=1050,
    title_x=0.5,
    template="ggplot2",
)
fig1 = fig1.update_traces(hovertemplate="Size: %{y} GB")
fig1.show()
```

```{r} 
r_mean_analyses_results_singles_data <- round(py$mean_analyses_results_singles_data)
r_mean_analyses_results_singles_disk <- round(py$mean_analyses_results_singles_disk)
r_mean_analyses_results_trios_data <-   round(py$mean_analyses_results_trios_data )
r_mean_analyses_results_trios_disk <-   round(py$mean_analyses_results_trios_disk )
r_mean_analyses_results_data <- py$mean_analyses_results_data
r_mean_analyses_results_disk <- py$mean_analyses_results_disk
```


::: {.callout-important}
### Subtotal

Average analyses-results singles folder size is
<code>`{r} r_mean_analyses_results_singles_data` GiB</code>
(<code>`{r} r_mean_analyses_results_singles_disk` GiB</code> on disk).

Average analyses-results trios folder size is 
<code>`{r} r_mean_analyses_results_trios_data` GiB</code>
(<code>`{r} r_mean_analyses_results_trios_disk` GiB</code> on disk).

[Adding [NovaSeqX generated data and analyses-work data](#bcl-convert-data-analyses-work)
and counting in the 2 duplicates of analyses-results, the total data per sample becomes
<code>`{r} round(61 + r_mean_analyses_work_data + r_mean_analyses_results_data*2)` GiB</code>
(<code>`{r} round(81 + r_mean_analyses_work_disk + r_mean_analyses_results_disk*2)` GiB</code> on disk).]{#bcl-convert-data-analyses-work-results}

:::

##### ella-incoming folder size
```{python}
#| cache: false
import plotly.graph_objects as go

ella_incoming_data =  [3.3, 3.4, 3.7, 4.2, 4.4, 5.2, 5.5, 6.3, 6.6, 7.0, 7.2, 7.6, 7.6, 7.8, 8.0, 9.3, 9.5, 9.7, 9.9, 10, 11, 11, 11, 12, 12, 14, 15, 15, 18, 25, 25, 26, 28, 30, 31, 34, 34, 35, 36, 43, 66, 66, 67, 128, 128, 129, 464, 469, 470, 470, 470, 473, 474, 475, 478, 480, 481, 487, 565]
ella_incoming_disk = [3.9, 4.1, 4.3, 4.8, 4.9, 5.6, 6.1, 6.7, 7.0, 7.4, 7.7, 8.0, 8.0, 8.2, 8.3, 9.7, 9.9, 9.9, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16, 18, 25, 25, 26, 29, 31, 31, 34, 34, 35, 36, 43, 67, 67, 68, 128, 129, 130, 466, 470, 471, 471, 471, 475, 475, 477, 479, 482, 482, 489, 566]

mean_ella_incoming_data = mean(ella_incoming_data)
mean_ella_incoming_disk = mean(ella_incoming_disk)

fig1 = go.Figure(
    data=[
        go.Box(y=ella_incoming_data, boxpoints="all", name="ella-incoming (logical)"),
        go.Box(y=ella_incoming_disk, boxpoints="all", name="ella-incoming (on disk)"),
    ]
)
fig1 = fig1.update_layout(
    title="ella-incoming directories size (MB)",
    yaxis_title="Size (MB)",
    height=600,
    width=1050,
    title_x=0.5,
    template="ggplot2",
)
fig1 = fig1.update_traces(hovertemplate="Size: %{y} MB")
fig1.show()
```


```{r} 
r_mean_ella_incoming_data <- round(py$mean_ella_incoming_data)
r_mean_ella_incoming_disk <- round(py$mean_ella_incoming_disk)
```

::: {.callout-important}
### Total

Average ella-incoming folder size is
<code>`{r} r_mean_ella_incoming_data` MB</code>
(<code>`{r} r_mean_ella_incoming_disk` MB</code> on disk).


Adding [NovaSeqX generated data, analyses-work data and analyses-results data](#bcl-convert-data-analyses-work-results),
the total data per sample becomes
<code>`{r} round(61 + r_mean_analyses_work_data + r_mean_analyses_results_data*2 + r_mean_ella_incoming_data/1000)` GiB</code>
(<code>`{r} round(81 + r_mean_analyses_work_disk + r_mean_analyses_results_disk*2 + r_mean_ella_incoming_disk/1000)` GiB</code> on disk).

:::

#### Number of samples BCL Convert only

```{ojs}
//| echo: false
//| panel: sidebar
md`Assuming diagnostics usable storage (<code>TiB</code>):`
viewof diag_storage = Inputs.range([0, 500], {value: 155, step: 1})
```

```{ojs}
//| echo: false
import {textcolor} from "@observablehq/text-color-annotations-in-markdown"

num_samples = diag_storage*1000/269
f_num_samples = num_samples.toFixed(0)
num_projects = num_samples/48
f_num_projects = num_projects.toFixed(1)
num_weeks = num_samples/192
f_num_weeks = num_weeks.toFixed(1)
num_25b_flowcells = num_samples/64
f_num_25b_flowcells = num_25b_flowcells.toFixed(1)

md`Which equals to the total data of:`
md`<code style="font-family: monospace;">${textcolor(f_num_samples.toString().padStart(5, '\u00A0'), 'MediumSeaGreen')}</code> samples`
md`<code style="font-family: monospace;">${textcolor(f_num_projects.toString().padStart(5, '\u00A0'), 'SlateBlue')}</code> projects (48 samples each project)`
md`<code style="font-family: monospace;">${textcolor(f_num_weeks.toString().padStart(5, '\u00A0'), 'Chocolate')}</code> weeks (192 samples per week)`
md`<code style="font-family: monospace;">${textcolor(f_num_25b_flowcells.toString().padStart(5, '\u00A0'), 'Chocolate')}</code> 25B flowcells (64 samples per flowcell)`
```


### DRAGEN Germline (AllVariantCallers)
When secondary analysis is DRAGEN Germline with all variant callers, _i.e._ doing both demultiplexing and variant
calling with Onboard DRAGEN.

Each sample has about `20 GB` pipeline output logical data (`27 GB` on disk) in addition.
See @sec-analysis-folder for pipeline output files and their sizes per sample.

::: {.callout-important}
### Total
In total, `81 GB` logical data per sample (`108 GB` on disk).

The inhouse pipeline and nsc-exporter changes to accommodate the DRAGEN Germline pipeline is not yet implemented.
Some duplication of NovaSeqX generated data is expected.
:::

#### Pipeline output files per sample{#sec-analysis-folder}

::: {style="font-family: courier;font-size:0.7rem"}
>analysis/wgs435_HB12345678_b08a0667-b221-48c6-8d44-abb516a61a2b/germline_seq    
>â”œâ”€â”€ [  20G]  germline_seq    
â”‚Â Â  â”œâ”€â”€ [ 2.6M]  report.html    
â”‚Â Â  â”œâ”€â”€ [  13M]  sv    
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [ 6.1M]  results    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [  44K]  stats    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [  736]  alignmentStatsSummary.txt    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [  20K]  candidate_metrics.csv    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [  535]  diploidSV.sv_metrics.csv    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [ 4.4K]  graph_metrics.csv    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [ 9.0K]  svCandidateGenerationStats.tsv    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ [ 6.7K]  svCandidateGenerationStats.xml    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ [ 1.7K]  svLocusGraphStats.tsv    
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ [ 6.1M]  variants    
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [ 4.2M]  candidateSV.vcf.gz    
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [ 671K]  candidateSV.vcf.gz.tbi    
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [ 1.1M]  diploidSV.vcf.gz    
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ [ 121K]  diploidSV.vcf.gz.tbi    
â”‚Â Â  â”‚Â Â  â””â”€â”€ [ 6.5M]  workspace    
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [  56K]  alignmentStats.xml    
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [  505]  chromDepth.txt    
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [  59K]  edgeRuntimeLog.txt    
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [  17K]  genomeSegmentScanDebugInfo.txt    
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ [ 2.3K]  logs    
â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ [ 2.2K]  config_log.txt    
â”‚Â Â  â”‚Â Â      â””â”€â”€ [ 6.4M]  svLocusGraph.bin    
â”‚Â Â  â”œâ”€â”€ [ 182K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.excluded_intervals.bed.gz    
â”‚Â Â  â”œâ”€â”€ [ 457K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.gff3    
â”‚Â Â  â”œâ”€â”€ [ 2.8K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.igv_session.xml    
â”‚Â Â  â”œâ”€â”€ [  793]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [  70K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.vcf.gz    
â”‚Â Â  â”œâ”€â”€ [   32]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.vcf.gz.md5sum    
â”‚Â Â  â”œâ”€â”€ [  18K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cnv.vcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [  [16G]{style="color:red"}]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cram    
â”‚Â Â  â”œâ”€â”€ [ 1.3M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cram.crai    
â”‚Â Â  â”œâ”€â”€ [   32]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cram.md5sum    
â”‚Â Â  â”œâ”€â”€ [  302]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cyp2b6.tsv    
â”‚Â Â  â”œâ”€â”€ [  283]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.cyp2d6.tsv    
â”‚Â Â  â”œâ”€â”€ [ 420K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.fastqc_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 272K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.fragment_length_hist.csv    
â”‚Â Â  â”œâ”€â”€ [  185]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.gba.tsv    
â”‚Â Â  â”œâ”€â”€ [ 2.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.gvcf_hethom_ratio_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 2.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.gvcf_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [  46M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.baf.bw    
â”‚Â Â  â”œâ”€â”€ [ [3.8G]{style="color:red"}]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.gvcf.gz    
â”‚Â Â  â”œâ”€â”€ [   32]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.gvcf.gz.md5sum    
â”‚Â Â  â”œâ”€â”€ [ 1.2M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.gvcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [ 365M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.vcf.gz    
â”‚Â Â  â”œâ”€â”€ [   32]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.vcf.gz.md5sum    
â”‚Â Â  â”œâ”€â”€ [ 1.6M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.hard-filtered.vcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [  16M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.improper.pairs.bw    
â”‚Â Â  â”œâ”€â”€ [  429]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.insert-stats.tab    
â”‚Â Â  â”œâ”€â”€ [ 8.9K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.mapping_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 9.2K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.metrics.json    
â”‚Â Â  â”œâ”€â”€ [  39K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.pcr-model-0.log    
â”‚Â Â  â”œâ”€â”€ [  115]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.pcr-model.log    
â”‚Â Â  â”œâ”€â”€ [ 1.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.ploidy_estimation_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 1.8K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.ploidy.vcf.gz    
â”‚Â Â  â”œâ”€â”€ [   32]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.ploidy.vcf.gz.md5sum    
â”‚Â Â  â”œâ”€â”€ [ 4.0K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.ploidy.vcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [ 1.9M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.repeats.bam    
â”‚Â Â  â”œâ”€â”€ [ 4.3K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.repeats.vcf.gz    
â”‚Â Â  â”œâ”€â”€ [ 3.9K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.repeats.vcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [  48K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.roh.bed    
â”‚Â Â  â”œâ”€â”€ [  114]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.roh_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 242K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.seg    
â”‚Â Â  â”œâ”€â”€ [  69K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.seg.bw    
â”‚Â Â  â”œâ”€â”€ [ 247K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.seg.called    
â”‚Â Â  â”œâ”€â”€ [ 259K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.seg.called.merged    
â”‚Â Â  â”œâ”€â”€ [  223]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.smn.tsv    
â”‚Â Â  â”œâ”€â”€ [ 1.7K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.snperror-sampler.log    
â”‚Â Â  â”œâ”€â”€ [  535]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.sv_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 1.1M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.sv.vcf.gz    
â”‚Â Â  â”œâ”€â”€ [ 121K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.sv.vcf.gz.tbi    
â”‚Â Â  â”œâ”€â”€ [  19M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.target.counts.bw    
â”‚Â Â  â”œâ”€â”€ [  22M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.target.counts.diploid.bw    
â”‚Â Â  â”œâ”€â”€ [  31M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.target.counts.gc-corrected.gz    
â”‚Â Â  â”œâ”€â”€ [  25M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.target.counts.gz    
â”‚Â Â  â”œâ”€â”€ [ 1.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.targeted.json    
â”‚Â Â  â”œâ”€â”€ [  22M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.tn.bw    
â”‚Â Â  â”œâ”€â”€ [  37M]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.tn.tsv.gz    
â”‚Â Â  â”œâ”€â”€ [ 1.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.trimmer_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 7.2K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.vc_hethom_ratio_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 2.4K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.vc_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [ 2.8K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.wgs_contig_mean_cov.csv    
â”‚Â Â  â”œâ”€â”€ [ 2.1K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.wgs_coverage_metrics.csv    
â”‚Â Â  â”œâ”€â”€ [  16K]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.wgs_fine_hist.csv    
â”‚Â Â  â”œâ”€â”€ [  558]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.wgs_hist.csv    
â”‚Â Â  â””â”€â”€ [   43]  wgs435_HB12345678_3c52f4e7-826d-40dd-bd98-f4356deeb098.wgs_overall_mean_cov.csv    
â””â”€â”€ [  11K]  logs  
\ \ \ \ â”œâ”€â”€ [  258]  bcl2fastq.dragen_events.csv  
\ \ \ \ â”œâ”€â”€ [ 1.1K]  cmdline_1198902.txt  
\ \ \ \ â”œâ”€â”€ [  608]  cmdline_1608030.txt    
\ \ \ \ â”œâ”€â”€ [ 1.1K]  cmdline_3358454.txt    
\ \ \ \ â”œâ”€â”€ [  219]  DCKR_RG-stderr_1608030.txt    
\ \ \ \ â”œâ”€â”€ [  461]  DCKR_RG-stdout_1608030.txt    
\ \ \ \ â”œâ”€â”€ [  250]  ora.dragen_events.csv    
\ \ \ \ â”œâ”€â”€ [    1]  ORA-stderr_1198902.txt    
\ \ \ \ â”œâ”€â”€ [ 3.9K]  ORA-stdout_1198902.txt    
\ \ \ \ â”œâ”€â”€ [    1]  P2FSW-stderr_3358454.txt    
\ \ \ \ â””â”€â”€ [ 2.4K]  P2FSW-stdout_3358454.txt    
:::

::: {.callout-tip}
ðŸ‘† Generated by `tree --du` which shows the actual file sizes instead of disk space used.
:::

#### Number of samples DRGEN Germline

```{ojs}
//| echo: false
//| panel: sidebar
md`Assuming diagnostics usable storage (<code>TiB</code>):`
viewof germ_diag_storage = Inputs.range([0, 500], {value: 155, step: 1})
```

```{ojs}
//| echo: false

germ_num_samples = germ_diag_storage*1000/108
f_germ_num_samples = germ_num_samples.toFixed(0)
germ_num_projects = germ_num_samples/48
f_germ_num_projects = germ_num_projects.toFixed(1)
germ_num_weeks = germ_num_samples/192
f_germ_num_weeks = germ_num_weeks.toFixed(1)
germ_num_25b_flowcells = germ_num_samples/64
f_germ_num_25b_flowcells = germ_num_25b_flowcells.toFixed(1)

md`Which equals to the total data of:`
md`<code style="font-family: monospace;">${textcolor(f_germ_num_samples.toString().padStart(5, '\u00A0'), 'MediumSeaGreen')}</code> samples`
md`<code style="font-family: monospace;">${textcolor(f_germ_num_projects.toString().padStart(5, '\u00A0'), 'SlateBlue')}</code> projects (48 samples each project)`
md`<code style="font-family: monospace;">${textcolor(f_germ_num_weeks.toString().padStart(5, '\u00A0'), 'Chocolate')}</code> weeks (192 samples per week)`
md`<code style="font-family: monospace;">${textcolor(f_germ_num_25b_flowcells.toString().padStart(5, '\u00A0'), 'Chocolate')}</code> 25B flowcells (64 samples per flowcell)`
```



## Per sequencing run
Each sequencing run can have different set up.

- Flowcell side: 
  - single side (single flowcell) 
  - both sides (dual flowcell)
- Flowcell type: 
  - 1.5B
  - 10B
  - 25B
- Secondary analysis:
  - BCL Convert
  - DRAGEN Germline
    - variant calling mode = None
    - variant calling mode = SmallVariantCaller
    - variant calling mode = AllVariantCallers _(Small, Structural, CNV, Repeat Expansions, ROH, CYP2D6 etc.)_

We normally run a single or dual 25B flowcell with BCL Convert only or DRAGEN Germline with all variant callers enabled.

### Single 25B flowcell; BCL Convert only
Single 25B flowcell (64 samples), secondary analysis is BCL Convert, _i.e._ only demultiplexing.

::: {.callout-important}
### Total
`3.9 TB` logical data (`5.1 TB` on disk).
:::

### Dual 25B flowcell; BCL Convert only
Dual 25B flowcell (128 samples), secondary analysis is BCL Convert, _i.e._ only demultiplexing.

::: {.callout-important}
### Total
`7.8 TB` logical data (`10.2 TB` on disk).
:::


### Dual 25B flowcell; DRAGEN Germline (AllVariantCallers)
Dual 25B flowcell (128 samples), secondary analysis is DRAGEN Germline with all variant callers enabled, _i.e._ doing both
demultiplexing and mapping, variant calling with Onboard DRAGEN.

::: {.callout-important}
### Total
`10.5 TB` logical data (`14.0 TB` on disk).
:::

